 
These are result breaking baseline. Note the innovation here was to make the meta_batch_size 2 which apparently drove the loss down to more manageable levels. 
python main.py --datasource=sinusoid --logdir=logs/sine7/  --norm=None --update_batch_size=100 --regularize_penal 0.0 --meta_lr .001 --update_lr .001 --metatrain_iterations=70000 --num_updates=20 --meta_batch_size=2 --limit_task=True --resume=True --train=False --test_set=True


